{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torch import Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/phuonglh/vlp/dat/nli/XNLI-1.0/vi.tok.jsonl\n"
     ]
    }
   ],
   "source": [
    "from os.path import expanduser\n",
    "home = expanduser(\"~\")\n",
    "path = home + \"/vlp/dat/nli/XNLI-1.0/vi.tok.jsonl\"\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VietnameseXNLI(Dataset):\n",
    "  def __init__(self, jsonlPath):\n",
    "    self.X = []\n",
    "    self.y = []\n",
    "    with open(jsonlPath) as f:\n",
    "      for line in f:\n",
    "        sample = json.loads(line)\n",
    "        self.X.append(sample[\"sentence1_tokenized\"] + \" </s> \" + sample[\"sentence2_tokenized\"])\n",
    "        self.y.append(sample[\"gold_label\"])\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.y)\n",
    "  \n",
    "  def __getitem__(self, i):\n",
    "    return self.X[i], self.y[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VietnameseXNLI(path)\n",
    "N = int(0.8*len(dataset))\n",
    "training, test = random_split(dataset, [N, len(dataset)-N], generator=Generator().manual_seed(12345))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(training, batch_size=32)\n",
    "test_loader = DataLoader(test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ừm không có gì sai với việc một phụ_huynh tặng tất_cả mọi thứ cô ấy có để ừ cho ừ cho một cá_nhân như ừ như bạn </s> Bố_mẹ có_thể cho con_cái nhiều quà_cáp .',\n",
       "  'Ngày_nay , những người Đức này thậm_chí không ở lại Hoa_Kỳ . </s> Những người Đức này được sử_dụng trên khắp châu Mỹ ngày này .',\n",
       "  'tôi sợ là , tôi nghĩ rằng tên anh ấy_là Anderson , một quý ông đang tìm_kiếm một chiếc vé độc_lập chống lại Reagan </s> Anderson đánh_bại Reagan .',\n",
       "  'Nếu có_khi nào tôi viết một cuốn tự_truyện , nó sẽ là từ_điển của những địa_danh và con_người được định_nghĩa theo tầm quan_trọng riêng . </s> Điều quan_trọng với tôi là tự_truyện của tôi có_thể được tiếp_cận dễ_dàng nhất .',\n",
       "  'Trong xe_ngựa kéo , bạn ghé thăm dân_làng đang thu_hoạch , cắt lông cừu , mài bột trong nhà_máy , dệt , và làmt móng ngựa . </s> Người_dân trong làng ăn_mặc như thời thuộc_địa .',\n",
       "  'Những người không giao_tiếp với các ngôn_ngữ liên_quan có_lẽ sẽ không có câu trả_lời cho những câu_hỏi tu_từ này , nhưng tôi cảm_thấy chắc_chắn rằng họ sẽ thích được tha_thứ sự_thật đáng ghét . </s> Những người không nói được ngôn_ngữ sẽ khó trả_lời .',\n",
       "  'Chẳng có gì ngoài sa_mạc ; có cây đan sâm trên đường đi . </s> Con đường vắng thật vắng_vẻ .',\n",
       "  'um tôi có một đứa con_gái nhỏ mười_tám tháng tuổi </s> Tôi có đông con .',\n",
       "  'Ít người biết đến của những cư_dân thời_kỳ đồ đá sớm nhất ở cực tây nam châu Âu . </s> Những người sống ở châu Âu trong thời_kỳ Đồ đá .',\n",
       "  'Không cần phải xin_lỗi vì vai_trò lãnh_đạo của chúng_tôi . </s> Lựa_chọn duy_nhất của chúng_tôi là tuân theo mọi hướng mà chúng_tôi được chỉ cho từ cấp trên và cấp cao hơn_nữa .',\n",
       "  'Nhưng nó không dừng lại trước dự_định của tay súng . </s> Pháo_thủ đã định bắn vũ_khí của anh_ta .',\n",
       "  'Các faaade của đền thờ Ramses_II là một trong những hình_ảnh lâu_dài nhất của Ai_Cập và mặc_dù bạn có_thể đã nhìn thấy chúng trong các bức ảnh , họ thực_sự ngoạn_mục trong thực_tế . </s> Các faaade là trong lăng_mộ của vua Tut .',\n",
       "  'Trong các tổ_chức hàng_đầu , phát_triển các quy_trình kinh_doanh đóng một vai_trò quan_trọng trong việc xác_định cách các trách_nhiệm quản_lý thông_tin được cấu_trúc và điều_chỉnh để đáp_ứng nhu_cầu thay_đổi . </s> Vì nhu_cầu không_bao_giờ thay_đổi , các quy_trình nghiệp_vụ không cần phải tiến hóa .',\n",
       "  'Kẻ bắt_giữ hẹn gặp Slahi vào tháng 10 năm 1999 . </s> Cuộc họp Slahi được tổ_chức vào tháng 10 năm 1999 .',\n",
       "  'Cả hai loại này đều có_thể được thay_đổi mà không làm thay_đổi cơ_chế đối_xứng codon-codon . </s> Những thay_đổi rất khắc_nghiệt .',\n",
       "  'Quần_đảo Saronic có mùa kéo dài_lâu hơn trải dài từ tháng Tư đến tháng Mười . </s> Các đảo Saronic có một mùa rõ_rệt .',\n",
       "  'phải , tôi cũng không hiểu điều gì khiến , anh biết đấy , sự_việc đã lao dốc để bị đánh_bại vào tháng 12 năm_ngoái bởi có bao_nhiêu phiếu bầu chỉ bằng vài trăm phiếu </s> Nó đạt tỉ_lệ 99 % .',\n",
       "  'Làm cho đầu của bạn với nhiệt Do_đó , tôi biết rằng bạn đi đến độ dài thêm để được từ_bi và chăm_sóc cho người khác . </s> Tôi biết bạn bỏ nhiều tiền để nuôi những người đang đói xung_quanh bạn .',\n",
       "  'Thêm vào đó , như chúng_ta đã biết , cuộc_sống xuất_hiện trên Trái_Đất chỉ một lần . </s> Cuộc_sống trên trái_đất có_thể đã xuất_hiện nhiều lần .',\n",
       "  'Thật vậy , Bios_Group có liên_quan đến việc phát_minh và tạo ra chúng . </s> Bios_Group đã dành rất nhiều tiền thô vào sáng_tạo của họ .',\n",
       "  'và sau đó điều thứ_hai tôi có_thể xem là những gì họ có_thể mua được </s> Tôi cũng nhìn vào những thứ có giá_cả phải_chăng đối_với họ .',\n",
       "  \"Điều rất thú_vị rằng Hillary_Rodham_Clinton có_thể có bất_cứ điều gì để học_hỏi từ Công_nương Diana là đủ hấp_dẫn để làm cho tôi nhấn vào Margaret_Carlson ' s Hillary và Di . </s> Hillary_Rodham_Clinton có_thể học_hỏi từ Công_nương Diana .\",\n",
       "  'Triết_lý pháp_lý của Liên_minh chiến_thắng , cả về chất và phong_cách . </s> Triết_lý pháp_lý đã chiến_thắng cả về mặt chất và phong_cách .',\n",
       "  'Một nhóm tại Hiệp_hội Quán_Bar của Thành_phố New_York , trong khi đó , đã thảo_luận về khoản nợ của sinh_viên trong sáu tháng . </s> Một người_ở Idaho chưa bao_giờ nghĩ về nợ sinh_viên .',\n",
       "  'Trang_phục bởi Brigitte_Doth , Jade_Stice , và Penny_Laimana . </s> Để tạo ra trang_phục này cần sự hợp sức của cả ba người .',\n",
       "  'Vào ban_đêm có nhiều nhà_hàng , câu_lạc_bộ và nhà_hát hay để thưởng_thức , và vào ban_ngày có bãi_biển rực_rỡ , hoàn_chỉnh với bến_tàu giải_trí , đu_quay cổ và khu mua_sắm gần đó . </s> Có rất nhiều nơi để khám_phá cả ngày lẫn đêm .',\n",
       "  'Tôi đã nói với anh_ấy , tôi đã cố_gắng giải_thích cho anh_ấy rằng tôi đã thất_vọng vì tôi không có đủ thông_tin tôi cần . </s> Tôi nói với anh_ấy tôi không muốn nghe bất_cứ điều gì khác .',\n",
       "  'Thưa ông , đất_nước là tất_cả , chủ_quyền chỉ là vô_ích . </s> Nhiều năm hỗn_loạn đã khiến đất_đai không ổn_định .',\n",
       "  'Ngoài việc nghiên_cứu cẩn_thận các hồ_sơ chính_thức khác_nhau , chính_phủ Séc cũng xem_xét các bức ảnh giám_sát được chụp bên ngoài đại_sứ_quán Iraq . </s> Chính_phủ Séc không có tài_liệu giám_sát .',\n",
       "  'Trong thực_tế , đó là điểm chớp_nhoáng cho các cuộc biểu_tình và bạo_loạn trong cuộc tranh_luận về xe_buýt trong những năm 1970 . </s> Có những cuộc biểu_tình chủng_tộc vào những năm 70 .',\n",
       "  'Các nhà ngôn_ngữ_học viết sách dường_như vẫn luôn_luôn là những học_giả đang muốn quảng_bá quan_điểm riêng của họ , một_số trong số các quan_điểm đó rất khó hiểu , ít_nhất mà nói là vậy . </s> Các nhà ngôn_ngữ_học kiếm rất nhiều tiền từ việc viết sách .',\n",
       "  'Từ một nhóm diễn_viên lưu_diễn năm 1973 bao_gồm sinh_viên ở các thành_phố như Gary , Elkhart , và Terre_Haute , ngày_nay đã trở_thành chương_trình giáo_dục IRT . </s> Một_số diễn_viên lưu_diễn ở Indiana năm 1973 .'),\n",
       " ('entailment',\n",
       "  'neutral',\n",
       "  'contradiction',\n",
       "  'contradiction',\n",
       "  'neutral',\n",
       "  'entailment',\n",
       "  'neutral',\n",
       "  'contradiction',\n",
       "  'entailment',\n",
       "  'contradiction',\n",
       "  'neutral',\n",
       "  'contradiction',\n",
       "  'contradiction',\n",
       "  'entailment',\n",
       "  'neutral',\n",
       "  'entailment',\n",
       "  'contradiction',\n",
       "  'neutral',\n",
       "  'neutral',\n",
       "  'neutral',\n",
       "  'entailment',\n",
       "  'entailment',\n",
       "  'entailment',\n",
       "  'contradiction',\n",
       "  'entailment',\n",
       "  'entailment',\n",
       "  'contradiction',\n",
       "  'neutral',\n",
       "  'contradiction',\n",
       "  'neutral',\n",
       "  'neutral',\n",
       "  'entailment')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ừm không có gì sai với việc một phụ_huynh tặng tất_cả mọi thứ cô ấy có để ừ cho ừ cho một cá_nhân như ừ như bạn </s> Bố_mẹ có_thể cho con_cái nhiều quà_cáp .',\n",
       " 'Ngày_nay , những người Đức này thậm_chí không ở lại Hoa_Kỳ . </s> Những người Đức này được sử_dụng trên khắp châu Mỹ ngày này .',\n",
       " 'tôi sợ là , tôi nghĩ rằng tên anh ấy_là Anderson , một quý ông đang tìm_kiếm một chiếc vé độc_lập chống lại Reagan </s> Anderson đánh_bại Reagan .',\n",
       " 'Nếu có_khi nào tôi viết một cuốn tự_truyện , nó sẽ là từ_điển của những địa_danh và con_người được định_nghĩa theo tầm quan_trọng riêng . </s> Điều quan_trọng với tôi là tự_truyện của tôi có_thể được tiếp_cận dễ_dàng nhất .',\n",
       " 'Trong xe_ngựa kéo , bạn ghé thăm dân_làng đang thu_hoạch , cắt lông cừu , mài bột trong nhà_máy , dệt , và làmt móng ngựa . </s> Người_dân trong làng ăn_mặc như thời thuộc_địa .',\n",
       " 'Những người không giao_tiếp với các ngôn_ngữ liên_quan có_lẽ sẽ không có câu trả_lời cho những câu_hỏi tu_từ này , nhưng tôi cảm_thấy chắc_chắn rằng họ sẽ thích được tha_thứ sự_thật đáng ghét . </s> Những người không nói được ngôn_ngữ sẽ khó trả_lời .',\n",
       " 'Chẳng có gì ngoài sa_mạc ; có cây đan sâm trên đường đi . </s> Con đường vắng thật vắng_vẻ .',\n",
       " 'um tôi có một đứa con_gái nhỏ mười_tám tháng tuổi </s> Tôi có đông con .',\n",
       " 'Ít người biết đến của những cư_dân thời_kỳ đồ đá sớm nhất ở cực tây nam châu Âu . </s> Những người sống ở châu Âu trong thời_kỳ Đồ đá .',\n",
       " 'Không cần phải xin_lỗi vì vai_trò lãnh_đạo của chúng_tôi . </s> Lựa_chọn duy_nhất của chúng_tôi là tuân theo mọi hướng mà chúng_tôi được chỉ cho từ cấp trên và cấp cao hơn_nữa .',\n",
       " 'Nhưng nó không dừng lại trước dự_định của tay súng . </s> Pháo_thủ đã định bắn vũ_khí của anh_ta .',\n",
       " 'Các faaade của đền thờ Ramses_II là một trong những hình_ảnh lâu_dài nhất của Ai_Cập và mặc_dù bạn có_thể đã nhìn thấy chúng trong các bức ảnh , họ thực_sự ngoạn_mục trong thực_tế . </s> Các faaade là trong lăng_mộ của vua Tut .',\n",
       " 'Trong các tổ_chức hàng_đầu , phát_triển các quy_trình kinh_doanh đóng một vai_trò quan_trọng trong việc xác_định cách các trách_nhiệm quản_lý thông_tin được cấu_trúc và điều_chỉnh để đáp_ứng nhu_cầu thay_đổi . </s> Vì nhu_cầu không_bao_giờ thay_đổi , các quy_trình nghiệp_vụ không cần phải tiến hóa .',\n",
       " 'Kẻ bắt_giữ hẹn gặp Slahi vào tháng 10 năm 1999 . </s> Cuộc họp Slahi được tổ_chức vào tháng 10 năm 1999 .',\n",
       " 'Cả hai loại này đều có_thể được thay_đổi mà không làm thay_đổi cơ_chế đối_xứng codon-codon . </s> Những thay_đổi rất khắc_nghiệt .',\n",
       " 'Quần_đảo Saronic có mùa kéo dài_lâu hơn trải dài từ tháng Tư đến tháng Mười . </s> Các đảo Saronic có một mùa rõ_rệt .',\n",
       " 'phải , tôi cũng không hiểu điều gì khiến , anh biết đấy , sự_việc đã lao dốc để bị đánh_bại vào tháng 12 năm_ngoái bởi có bao_nhiêu phiếu bầu chỉ bằng vài trăm phiếu </s> Nó đạt tỉ_lệ 99 % .',\n",
       " 'Làm cho đầu của bạn với nhiệt Do_đó , tôi biết rằng bạn đi đến độ dài thêm để được từ_bi và chăm_sóc cho người khác . </s> Tôi biết bạn bỏ nhiều tiền để nuôi những người đang đói xung_quanh bạn .',\n",
       " 'Thêm vào đó , như chúng_ta đã biết , cuộc_sống xuất_hiện trên Trái_Đất chỉ một lần . </s> Cuộc_sống trên trái_đất có_thể đã xuất_hiện nhiều lần .',\n",
       " 'Thật vậy , Bios_Group có liên_quan đến việc phát_minh và tạo ra chúng . </s> Bios_Group đã dành rất nhiều tiền thô vào sáng_tạo của họ .',\n",
       " 'và sau đó điều thứ_hai tôi có_thể xem là những gì họ có_thể mua được </s> Tôi cũng nhìn vào những thứ có giá_cả phải_chăng đối_với họ .',\n",
       " \"Điều rất thú_vị rằng Hillary_Rodham_Clinton có_thể có bất_cứ điều gì để học_hỏi từ Công_nương Diana là đủ hấp_dẫn để làm cho tôi nhấn vào Margaret_Carlson ' s Hillary và Di . </s> Hillary_Rodham_Clinton có_thể học_hỏi từ Công_nương Diana .\",\n",
       " 'Triết_lý pháp_lý của Liên_minh chiến_thắng , cả về chất và phong_cách . </s> Triết_lý pháp_lý đã chiến_thắng cả về mặt chất và phong_cách .',\n",
       " 'Một nhóm tại Hiệp_hội Quán_Bar của Thành_phố New_York , trong khi đó , đã thảo_luận về khoản nợ của sinh_viên trong sáu tháng . </s> Một người_ở Idaho chưa bao_giờ nghĩ về nợ sinh_viên .',\n",
       " 'Trang_phục bởi Brigitte_Doth , Jade_Stice , và Penny_Laimana . </s> Để tạo ra trang_phục này cần sự hợp sức của cả ba người .',\n",
       " 'Vào ban_đêm có nhiều nhà_hàng , câu_lạc_bộ và nhà_hát hay để thưởng_thức , và vào ban_ngày có bãi_biển rực_rỡ , hoàn_chỉnh với bến_tàu giải_trí , đu_quay cổ và khu mua_sắm gần đó . </s> Có rất nhiều nơi để khám_phá cả ngày lẫn đêm .',\n",
       " 'Tôi đã nói với anh_ấy , tôi đã cố_gắng giải_thích cho anh_ấy rằng tôi đã thất_vọng vì tôi không có đủ thông_tin tôi cần . </s> Tôi nói với anh_ấy tôi không muốn nghe bất_cứ điều gì khác .',\n",
       " 'Thưa ông , đất_nước là tất_cả , chủ_quyền chỉ là vô_ích . </s> Nhiều năm hỗn_loạn đã khiến đất_đai không ổn_định .',\n",
       " 'Ngoài việc nghiên_cứu cẩn_thận các hồ_sơ chính_thức khác_nhau , chính_phủ Séc cũng xem_xét các bức ảnh giám_sát được chụp bên ngoài đại_sứ_quán Iraq . </s> Chính_phủ Séc không có tài_liệu giám_sát .',\n",
       " 'Trong thực_tế , đó là điểm chớp_nhoáng cho các cuộc biểu_tình và bạo_loạn trong cuộc tranh_luận về xe_buýt trong những năm 1970 . </s> Có những cuộc biểu_tình chủng_tộc vào những năm 70 .',\n",
       " 'Các nhà ngôn_ngữ_học viết sách dường_như vẫn luôn_luôn là những học_giả đang muốn quảng_bá quan_điểm riêng của họ , một_số trong số các quan_điểm đó rất khó hiểu , ít_nhất mà nói là vậy . </s> Các nhà ngôn_ngữ_học kiếm rất nhiều tiền từ việc viết sách .',\n",
       " 'Từ một nhóm diễn_viên lưu_diễn năm 1973 bao_gồm sinh_viên ở các thành_phố như Gary , Elkhart , và Terre_Haute , ngày_nay đã trở_thành chương_trình giáo_dục IRT . </s> Một_số diễn_viên lưu_diễn ở Indiana năm 1973 .')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(test_loader))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "bert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizer(name_or_path='vinai/phobert-base', vocab_size=64000, model_max_len=256, is_fast=False, padding_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {\"entailment\": 0, \"neutral\": 1, \"contradiction\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorify(batch):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for x, y in zip(batch[0], batch[1]):\n",
    "      u = torch.tensor([tokenizer.encode(x)])\n",
    "      v = torch.tensor([labels[y]])\n",
    "      xs.append(u)\n",
    "      ys.append(v)\n",
    "    return (xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([[    0, 14583,   599,    17,    10,   148,  1069,    15,    49,    16,\n",
       "            1635,   806,   392,   207,   129,   106,   241,    10,    24,  6236,\n",
       "              13,  6236,    13,    16,   435,    42,  6236,    42,    88,     2,\n",
       "            7026,    62,    13,  2974,    36, 32780,     5,     2]]),\n",
       "  tensor([[   0, 6177,    4,   21,   18,  357,   23,  644,   17,   25,   44, 1428,\n",
       "              5,    2,  217,   18,  357,   23,   11,  117,   34, 1270, 2935,   93,\n",
       "             43,   23,    5,    2]]),\n",
       "  tensor([[    0,    70,  1080,     8,     4,    70,   487,    87,   221,    83,\n",
       "           25190,     8, 13641,     4,    16,   882,    46,    52,   885,    16,\n",
       "             152,   826,  1912,   335,    44, 39336,     2, 13641,  2424, 39336,\n",
       "               5,     2]]),\n",
       "  tensor([[    0,   313,  4012,   142,    70,   467,    16,  1088, 13811,     4,\n",
       "             231,    38,     8, 16231,     7,    21,  7723,     6,   754,    11,\n",
       "            8409,    63,   748,   331,   465,     5,     2,   432,   331,    15,\n",
       "              70,     8, 13811,     7,    70,    62,    11,  1274,  1047,    67,\n",
       "               5,     2]]),\n",
       "  tensor([[    0,    92, 26794,  1300,     4,    88,  4136,   745,  7014,    52,\n",
       "            2881,     4,   919,  3228,  7590,     4, 12094,  1887,    12,  1100,\n",
       "               4,  7159,     4,     6, 11567,  1387,  1204,  4167,  3053,     5,\n",
       "               2,  2191,    12,   632,  4881,    42,   790, 43683,     5,     2]]),\n",
       "  tensor([[    0,   217,    18,    17,  3767,    15,     9,  2877,   314,  1592,\n",
       "              38,    17,    10,   528,   799,    13,    21, 24069,   447,  1187,\n",
       "           14279,  6236,    23,     4,    51,    70,   841,   994,    87,    86,\n",
       "              38,   543,    11,  6979,  2360,   463,  5853,     5,     2,   217,\n",
       "              18,    17,    96,    11,  2877,    38,   359,   799,     5,     2]]),\n",
       "  tensor([[    0,  4978,    10,   148,   227,  7296,    65,    10,   368,  8072,\n",
       "            5760,    34,   109,    57,     5,     2,  1322,   109,  3543,   520,\n",
       "           15354,     5,     2]]),\n",
       "  tensor([[    0,  3465,    70,    10,    16,   802,  9443,   238,   239, 40275,\n",
       "              78,   126,     2,   218,    10,   553,    73,     5,     2]]),\n",
       "  tensor([[    0,  8265,    18,    55,    30,     7,    21,  1838,  2055,   779,\n",
       "             494,   471,    67,    25,  1634,  2615,   542,  2935,  8311,     5,\n",
       "               2,   217,    18,   235,    25,  2935,  8311,    12,  2055, 10952,\n",
       "             494,     5,     2]]),\n",
       "  tensor([[    0,   453,   115,    41,  2414,    90,   709,   393,     7,   283,\n",
       "               5,     2, 11557,  1155,     7,   283,     8,  8400,    63,   207,\n",
       "             455,    64,   283,    11,    66,    13,    39,   181,    34,     6,\n",
       "             181,    84,  1483,     5,     2]]),\n",
       "  tensor([[    0,   293,   231,    17,   772,    44,    71,  3320,     7,   306,\n",
       "            1099,     5,     2,  9587,    14,  2608,   943,   991,     7, 35699,\n",
       "            1517,     5,     2]]),\n",
       "  tensor([[    0,   146, 15884,  1850, 10032,     7,  2279,  3213,  8374,  1302,\n",
       "            6989,  1966,     8,    16,    12,    21,   425,  2250,    67,     7,\n",
       "            2800,     6,  1695,    88,    62,    14,   364,   108,   572,    12,\n",
       "               9,   711,   284,     4,    86,   742,  6546,    12,   573,     5,\n",
       "               2,   146, 15884,  1850, 10032,     8,    12, 11577,     7,  1692,\n",
       "            4601,  1204,     5,     2]]),\n",
       "  tensor([[    0,    92,     9,   116,  1138,     4,   134,     9,  1844,   329,\n",
       "             580,    16,   709,   331,    12,    49,   600,   139,     9,   476,\n",
       "             260,   195,    11,  3424,     6,   947,    24,   875,   634,   411,\n",
       "               5,     2,  1023,   634, 15146,   789,   411,     4,     9,  1844,\n",
       "            2729,    17,   115,    41,  1447,  1340, 11095,  1517,     5,     2]]),\n",
       "  tensor([[   0, 7701, 1484, 2973,  243,  870, 4189, 9599,   33,   78,  210,   29,\n",
       "           3480,    5,    2, 1502,  673,  870, 4189, 9599,   11,  116,   33,   78,\n",
       "            210,   29, 3480,    5,    2]]),\n",
       "  tensor([[    0,  1351,    82,   166,    23,   131,    62,    11,   411,    64,\n",
       "              17,    47,   411,  1459, 15825,  2479,  2801,  5245,  2479,  7009,\n",
       "               5,     2,   217,   411,    59,  5324,     5,     2]]),\n",
       "  tensor([[    0, 18201,  8027, 29916,    10,   303,  1300, 24059,    48,  1289,\n",
       "             363,    39,    78,  3992,    30,    78,  7006,     5,     2,   146,\n",
       "             705,  8027, 29916,    10,    16,   303,  4956,     5,     2]]),\n",
       "  tensor([[   0,   41,    4,   70,   32,   17,  563,  184,  148,  122,    4,   83,\n",
       "             55, 1582,    4, 1240,   14, 1750, 3419,   24,   45, 2424,   33,   78,\n",
       "            445, 1669,  223,   10, 1823, 2210, 1083,   66,  121,  515,  877, 2210,\n",
       "              2, 1244,  208, 3105, 4424, 5938,    5,    2]]),\n",
       "  tensor([[    0,  2590,    13,   127,     7,    88,    15,  2515,  1528,     4,\n",
       "              70,    55,    87,    88,    57,    30,   378,   363,   143,    24,\n",
       "              11, 29388,     6,   838,    13,    18,    85,     5,     2,   218,\n",
       "              55,    88,   338,    36,   123,    24,   695,    21,    18,    52,\n",
       "            3442,  1215,    88,     5,     2]]),\n",
       "  tensor([[   0, 2855,   33,   37,    4,   42,  507,   14,   55,    4,  491,  395,\n",
       "             34, 6098,   66,   16,  101,    5,    2, 3841,   34, 6876,   62,   14,\n",
       "            395,   36,  101,    5,    2]]),\n",
       "  tensor([[    0,  3395,   702,     4,  5732,  3603, 22615,    10,   314,    30,\n",
       "              49,  8768,     6,   199,    40,   572,     5,     2,  5732,  3603,\n",
       "           22615,    14,   365,    59,    36,   123,  6449,    33,  1181,     7,\n",
       "              86,     5,     2]]),\n",
       "  tensor([[    0,     6,    53,    37,   184, 26286,  6873,   277,    70,    62,\n",
       "             305,     8,    21,   148,    86,    62,   188,    11,     2,   218,\n",
       "              32,   364,    33,    21,   129,    10,  3401,  7997,   190,    86,\n",
       "               5,     2]]),\n",
       "  tensor([[    0,   432,    59,  1748,    87, 21680, 14136, 24367, 32748,  5940,\n",
       "              62,    10,  1153,   184,   148,    24,  3559,    39, 15749, 17087,\n",
       "               8,   312,  1136,    24,    47,    13,    70,  2631,    33, 32432,\n",
       "           18768,  3421,   104,  1118, 16109,     6,  9195,     5,     2, 21680,\n",
       "           14136, 24367, 32748,  5940,    62,  3559,    39, 15749, 17087,     5,\n",
       "               2]]),\n",
       "  tensor([[    0, 36868,  2089,     7,  2739,   812,     4,    94,    28,   567,\n",
       "               6,  1288,     5,     2, 36868,  2089,    14,   812,    94,    28,\n",
       "             373,   567,     6,  1288,     5,     2]]),\n",
       "  tensor([[    0,   242,   276,    35,  2022, 12267, 20279,     7,  1375,  2647,\n",
       "               4,    12,    26,    37,     4,    14,  1700,    28,   666,   758,\n",
       "               7,   649,    12,  3158,    78,     5,     2,   242, 25134,    25,\n",
       "           50885,   102,   789,   487,    28,   758,   649,     5,     2]]),\n",
       "  tensor([[    0, 10504,   223, 44186, 52416,  4448,  4525,     4, 39576,  5868,\n",
       "           48143,     4,     6, 26665,  2465,  6454,  3536,  2986,     5,     2,\n",
       "             483,   199,    40,  1390,    23,   115,    61,  2288,   760,     7,\n",
       "              94,   346,    18,     5,     2]]),\n",
       "  tensor([[    0,  1203,  4893,    10,    36,  1953,     4,  3247,     6,  6554,\n",
       "             118,    24,  2483,     4,     6,    33,  6285,    10, 31548,   262,\n",
       "            3820,     4,  4691,    15, 22486,  1538,     4, 50756,   862,     6,\n",
       "             316,  2063,   124,    37,     5,     2,   503,    59,    36,   189,\n",
       "              24,  2513,    94,    43,  1137,   396,     5,     2]]),\n",
       "  tensor([[   0,  218,   14,   96,   15, 9856,  241,    4,   70,   14,  977, 1610,\n",
       "             13, 9856,  241,   87,   70,   14, 2804,   90,   70,   17,   10,  312,\n",
       "            195,   70,  115,    5,    2,  218,   96,   15, 9856,  241,   70,   17,\n",
       "            202,  523, 1153,  184,  148,   85,    5,    2]]),\n",
       "  tensor([[    0,  8445,    46,     4,   794,     8,   392,     4,  2495,    66,\n",
       "               8, 19778,     5,     2,   449,    29,  7416,    14,   122,  2563,\n",
       "              17,   726,     5,     2]]),\n",
       "  tensor([[    0,  1004,    49,   410,  3289,     9,   735,   495, 58674,   138,\n",
       "               4,   926,  9094,    32,   935,     9,   711,   284,   929,    11,\n",
       "             690,   145,   227, 12099,  1861,     5,     2,   315,  9094,    17,\n",
       "              10,  1715,   929,     5,     2]]),\n",
       "  tensor([[    0,    92,   573,     4,    37,     8,   192, 15554,    13,     9,\n",
       "             110,  2464,     6, 14410,    12,   110,  4217,    28,  2650,    12,\n",
       "              21,    29,  5567,     5,     2,   503,    21,   110,  2464,  9186,\n",
       "              33,    21,    29,  1663,     5,     2]]),\n",
       "  tensor([[    0,   146,    69, 34387,   467,   713,  1836,    74,  5757,     8,\n",
       "              21,  7938,    52,   202,  2524,  1233,   465,     7,    86,     4,\n",
       "             172,    12,   100,     9,  1233,    37,    59,   359,   563,     4,\n",
       "            1371,    64,    96,     8,   702,     5,     2,   146,    69, 34387,\n",
       "            1095,    59,    36,   123,    39,    49,   467,   713,     5,     2]]),\n",
       "  tensor([[    0,   404,    16,   276,   638,  8586,    29,  7189,   646,   649,\n",
       "              25,     9,   214,    42, 38454,     4,  4315,  3014, 10191,     4,\n",
       "               6, 43037,  1718, 27299,  3915,     4,  2709,    14,   299,   270,\n",
       "             606,  1622,  6043,     5,     2,  1146,   638,  8586,    25, 21609,\n",
       "              29,  7189,     5,     2]])],\n",
       " [tensor([0]),\n",
       "  tensor([1]),\n",
       "  tensor([2]),\n",
       "  tensor([2]),\n",
       "  tensor([1]),\n",
       "  tensor([0]),\n",
       "  tensor([1]),\n",
       "  tensor([2]),\n",
       "  tensor([0]),\n",
       "  tensor([2]),\n",
       "  tensor([1]),\n",
       "  tensor([2]),\n",
       "  tensor([2]),\n",
       "  tensor([0]),\n",
       "  tensor([1]),\n",
       "  tensor([0]),\n",
       "  tensor([2]),\n",
       "  tensor([1]),\n",
       "  tensor([1]),\n",
       "  tensor([1]),\n",
       "  tensor([0]),\n",
       "  tensor([0]),\n",
       "  tensor([0]),\n",
       "  tensor([2]),\n",
       "  tensor([0]),\n",
       "  tensor([0]),\n",
       "  tensor([2]),\n",
       "  tensor([1]),\n",
       "  tensor([2]),\n",
       "  tensor([1]),\n",
       "  tensor([1]),\n",
       "  tensor([0])])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorify(next(iter(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
