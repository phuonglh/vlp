# read whole data
val path = "/Users/phuonglh/vlp/woz/dat/woz/data/MultiWOZ_2.2/dev/dialogues_001.json"
val df = spark.read.option("multiline", "true").json(path)
df.printSchema
df.count

# filter single domain dialogues
import org.apache.spark.sql.functions._
val ef = df.filter(col("dialogue_id").startsWith("SNG"))
ef.count

ef.show

+-------------+------------+--------------------+
|  dialogue_id|    services|               turns|
+-------------+------------+--------------------+
|SNG01627.json|      [taxi]|[{[{[], taxi, [{n...|
| SNG0329.json|     [train]|[{[{[], train, []...|
|SNG01735.json|      [taxi]|[{[{[], taxi, [{n...|
| SNG0551.json|[restaurant]|[{[{[], restauran...|
|SNG01993.json|     [train]|[{[{[], train, []...|
|SNG02071.json|[restaurant]|[{[{[], restauran...|
| SNG0899.json|     [hotel]|[{[{[], hotel, [{...|
| SNG0759.json|     [hotel]|[{[{[], hotel, [{...|
|SNG01598.json|      [taxi]|[{[{[], taxi, [{n...|
|SNG01184.json|[restaurant]|[{[{[], restauran...|
| SNG1049.json|     [hotel]|[{[{[], hotel, []...|
|SNG02346.json|     [train]|[{[{[], train, []...|
| SNG0665.json|[restaurant]|[{[{[], restauran...|
| SNG0374.json|     [train]|[{[{[], train, [{...|
| SNG0041.json|      [taxi]|[{[{[], taxi, [],...|
| SNG0651.json|[restaurant]|[{[{[], restauran...|
|SNG02221.json|     [train]|[{[{[], train, [{...|
| SNG1046.json|     [hotel]|[{[{[], hotel, []...|
| SNG0807.json|     [hotel]|[{[{[], hotel, []...|
| SNG1143.json|[attraction]|[{[{[], attractio...|
+-------------+------------+--------------------+

# convert to our schema 
val ff = ef.as[Dialogue]

# filter dialogue in the restaurant domain
val gf = ff.filter(exists(col("services"), _.contains("restaurant")))

# flat map all the turns of the dialogues using the `turns` field
val hf = gf.flatMap(_.turns)
hf.count 
hf.show

+--------------------+-------+-------+--------------------+
|              frames|speaker|turn_id|           utterance|
+--------------------+-------+-------+--------------------+
|[{[], restaurant,...|   USER|      0|I am looking for ...|
|                  []| SYSTEM|      1|It is an expensiv...|
|[{[], restaurant,...|   USER|      2|Yes, I would. Ple...|
|                  []| SYSTEM|      3|Alright, I've boo...|
|[{[], restaurant,...|   USER|      4|Thanks, that's al...|
|                  []| SYSTEM|      5|You too, enjoy yo...|
|[{[], restaurant,...|   USER|      0|Could you tell me...|
|                  []| SYSTEM|      1|I have them at 18...|
|[{[], restaurant,...|   USER|      2|Great! Do you kno...|
|                  []| SYSTEM|      3|Sure, they are in...|
|[{[], restaurant,...|   USER|      4|   Thanks, good bye.|
|                  []| SYSTEM|      5|You're welcome. H...|
|[{[], restaurant,...|   USER|      0|Can you help me f...|
|[{[], restaurant,...| SYSTEM|      1|There is Sala Tho...|
|[{[], restaurant,...|   USER|      2|Yes, that would b...|
|                  []| SYSTEM|      3|Can you please te...|
|[{[], restaurant,...|   USER|      4|Thursday at 12:45...|
|                  []| SYSTEM|      5|I was able to boo...|
|[{[], restaurant,...|   USER|      6|thank you for you...|
|                  []| SYSTEM|      7|You are quite wel...|
+--------------------+-------+-------+--------------------+

# flat map all the frames, keep `speaker` and `utterance` along the way
# since the dialogues are in a single domain, we filter out out-of-domain frames because they are all empty
val kf = hf.flatMap(turn => turn.frames.filter(_.service == "restaurant").map((turn.speaker, turn.utterance, _))).toDF("speaker", "utterance", "frame")
kf.show

+-------+--------------------+--------------------+
|speaker|           utterance|               frame|
+-------+--------------------+--------------------+
|   USER|I am looking for ...|{[], restaurant, ...|
|   USER|Yes, I would. Ple...|{[], restaurant, ...|
|   USER|Thanks, that's al...|{[], restaurant, ...|
|   USER|Could you tell me...|{[], restaurant, ...|
|   USER|Great! Do you kno...|{[], restaurant, ...|
|   USER|   Thanks, good bye.|{[], restaurant, ...|
|   USER|Can you help me f...|{[], restaurant, ...|
| SYSTEM|There is Sala Tho...|{[], restaurant, ...|
|   USER|Yes, that would b...|{[], restaurant, ...|
|   USER|Thursday at 12:45...|{[], restaurant, ...|
|   USER|thank you for you...|{[], restaurant, ...|
|   USER|No, the reservati...|{[], restaurant, ...|
|   USER|Hi, I'm looking f...|{[], restaurant, ...|
|   USER|I'd like somethin...|{[], restaurant, ...|
| SYSTEM|Most of the expen...|{[], restaurant, ...|
|   USER|That sounds nice!...|{[], restaurant, ...|
|   USER|No, that's everyt...|{[], restaurant, ...|
|   USER|Hi there. I'm try...|{[], restaurant, ...|
|   USER|Not really, if yo...|{[], restaurant, ...|
|   USER|Thanks! That's al...|{[], restaurant, ...|
+-------+--------------------+--------------------+

=====
Window functions:

import org.apache.spark.sql.expressions.Window

val w = Window.partitionBy("dialogId").orderBy(col("turnId").cast("int"))
val df2 = df1.withColumn("acts(-3)", lag("actNames", 3).over(w))
val df3 = df2.withColumn("acts(-2)", lag("actNames", 2).over(w))
val df4 = df3.withColumn("acts(-1)", lag("actNames", 1).over(w))